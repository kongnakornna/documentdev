## ระบบศูนย์บริการรถยนต์ออนไลน์
- ระบบศูนย์บริการรถยนต์ออนไลน์ที่ออกแบบนี้เป็นสถาปัตยกรรมแบบ Microservices  
- ใช้เทคโนโลยีที่ทันสมัยและประสิทธิภาพสูง โดยแบ่งเป็นส่วนประกอบหลัก 5 ส่วนที่ทำงานร่วมกันอย่างมีประสิทธิภาพ

### สถาปัตยกรรมระบบ API
## Frontend  ส่วนหน้า  
- ระบบ API แรกใช้ Node.js กับ Nuxt.js framework พร้อม ORM สำหรับจัดการฐานข้อมูลและ JWT authentication สำหรับการยืนยันตัวตน 
- ระบบนี้รับผิดชอบในการจัดการคำขอจากส่วนหน้า (Frontend) โดยใช้ HTTP-only cookies เพื่อเพิ่มความปลอดภัย 
- และมีการ generate JWT token ที่มีอายุ 7 วัน  
- ส่วนนี้เหมาะสำหรับจัดการ user authentication, 
- session management 
- และ API endpoints สำหรับการโต้ตอบกับผู้ใช้โดยตรง

### ระบบ Frontend และฐานข้อมูล

1. ReactJS Frontend
- ส่วนหน้าใช้ ReactJS ซึ่งเป็น component-based architecture ที่มี virtual DOM สำหรับการ render ที่มีประสิทธิภาพ  
- แยก components เป็น Presentational Components (UI only) 
- Container Components (state และ logic management)  
- ใช้ React Hooks เช่น useState, useEffect, useContext
- useReducer สำหรับจัดการ state อย่างมีประสิทธิภาพ  
- สำหรับการเรียก API ใช้ Axios พร้อมกับ React.lazy() สำหรับ lazy loading เพื่อลด bundle size

2. Backend  (ระบบ API)  Nestjs Framework
- Apache Kafka + Java Spring Boot ทำหน้าที่เป็น producer และ consumer ของ Kafka โดยใช้ KafkaTemplate สำหรับส่งข้อความและ @KafkaListener สำหรับรับข้อความ  
- ส่วนนี้ สำหรับจัดการ business logic ที่ซับซ้อน เช่น การจัดการคิวงานซ่อม การแจ้งเตือน และการประมวลผลข้อมูลแบบ asynchronous
- Apache Kafka + Java Spring Boot ระบบ Flow สำหรับ Spring Boot + Kafka (Producer & Consumer)
- ระบบศูนย์บริการรถยนต์ออนไลน์ที่ใช้ Spring Boot กับ Apache Kafka จะออกแบบเป็นสถาปัตยกรรมแบบ event-driven ที่ microservices สื่อสารกันผ่าน events  
- ระบบนี้แบ่งเป็น 4 กระบวนการหลักที่ทำงานร่วมกันอย่างมีประสิทธิภาพ
  
**Producers (ส่งข้อความ)**

- API Gateway Service - รับ HTTP requests จาก frontend
- Booking Service - จัดการการจองนัดหมาย
- Repair Service - จัดการงานซ่อม
- Payment Service - ประมวลผลการชำระเงิน

**Kafka Cluster**

- Topics: `booking-events`, `repair-events`, `payment-events`, `notification-events`
- Partitions: แต่ละ topic มี 10 partitions เพื่อรองรับการประมวลผลแบบ parallel
- Replication Factor: 3 เพื่อความปลอดภัยของข้อมูล

**Consumers (รับข้อความ)**
- Notification Service - ส่งการแจ้งเตือนให้ลูกค้าและพนักงาน
- Analytics Service - วิเคราะห์ข้อมูลและสร้างรายงาน
- Cache Sync Service - อัพเดท Redis cache
- Audit Service - บันทึก audit logs

## Flow 1: การจองนัดหมายบริการ (Booking Flow)
### ขั้นตอนการทำงาน

**1. ลูกค้าสร้างการจอง**
```
ReactJS Frontend → POST /api/v1/bookings (customerId, vehicleId, serviceType, bookingDate)
```
**2. Booking Service (Producer)**
```java
        // ตรวจสอบความพร้อม
        if (isSlotAvailable(bookingDate)) {
            // บันทึกลง PostgreSQL
            Booking booking = bookingRepository.save(newBooking);
            
            // อัพเดท Redis cache
            redisTemplate.opsForValue().set("booking:" + booking.getId(), booking);
            
            // สร้าง Event
            BookingCreatedEvent event = BookingCreatedEvent.builder()
                .eventId(UUID.randomUUID().toString())
                .eventType("BOOKING_CREATED")
                .bookingId(booking.getId())
                .customerId(booking.getCustomerId())
                .bookingDate(booking.getBookingDate())
                .timestamp(Instant.now())
                .build();
            
            // Publish ไปยัง Kafka
            kafkaTemplate.send("booking-events", booking.getId(), event);
        }
```
**3. Consumers รับและประมวลผล**
```java
    // Notification Service Consumer
    @KafkaListener(topics = "booking-events", groupId = "notification-group")
    public void handleBookingEvent(BookingCreatedEvent event) {
        // ส่งอีเมล/SMS ยืนยันการจอง
        notificationService.sendBookingConfirmation(event);
        
        // ส่ง push notification
        fcmService.sendNotification(event.getCustomerId(), 
            "การจองของคุณได้รับการยืนยันแล้ว");
    }

// Analytics Service Consumer
    @KafkaListener(topics = "booking-events", groupId = "analytics-group")
    public void analyzeBooking(BookingCreatedEvent event) {
        // บันทึกข้อมูลสำหรับ dashboard
        analyticsRepository.recordBooking(event);
        
        // อัพเดทสถิติ real-time
        redisTemplate.opsForValue().increment("daily:bookings:" + LocalDate.now());
    }

// Audit Service Consumer
    @KafkaListener(topics = "booking-events", groupId = "audit-group")
    public void auditBooking(BookingCreatedEvent event) {
        // บันทึก audit log
        auditLogRepository.save(AuditLog.from(event));
}
```
## Flow 2: กระบวนการซ่อม (Repair Flow)
### Event-Driven Repair Workflow
**1. เริ่มงานซ่อม**
```
    Technician App → POST /api/v1/repairs/start(bookingId, technicianId, estimatedTime)
    Repair Service (Producer) →
        ├─ Save to PostgreSQL
        ├─ Update Redis cache
        └─ Publish "REPAIR_STARTED" event to Kafka
```
**2. อัพเดทสถานะระหว่างซ่อม**

```java
    // สร้าง multiple events ตามสถานะ
    RepairStatusEvent event = RepairStatusEvent.builder()
        .eventType("REPAIR_IN_PROGRESS")
        .status("DIAGNOSING") // → REPAIRING → TESTING
        .progressPercentage(25)
        .build();
    kafkaTemplate.send("repair-events", repairId, event);
```

**3. Real-time Status Updates**
```java
    // Consumer อัพเดทข้อมูลให้ลูกค้าเห็น real-time
    @KafkaListener(topics = "repair-events", groupId = "status-update-group")
    public void updateRepairStatus(RepairStatusEvent event) {
        // อัพเดท Redis สำหรับ real-time query
        redisTemplate.opsForHash().put(
            "repair:status:" + event.getRepairId(),
            "progress", event.getProgressPercentage()
        );
        // ส่ง notification ให้ลูกค้า
        webSocketService.sendToUser(event.getCustomerId(), event);
    }
```

**4. ซ่อมเสร็จสิ้น**
```
    Repair Service → Publish "REPAIR_COMPLETED" event
                ↓
    Payment Service Consumer → สร้างใบแจ้งหนี้
    Notification Service → แจ้งเตือนลูกค้ามารับรถ
    Inventory Service → อัพเดท stock อะไหล่
```

## Flow 3: การชำระเงิน (Payment Flow)
### Event Chain Pattern

**1. สร้าง Invoice**
```java
        // Payment Service รอ REPAIR_COMPLETED event
        @KafkaListener(topics = "repair-events")
        public void onRepairCompleted(RepairCompletedEvent event) {
            // สร้าง invoice
            Invoice invoice = invoiceService.createInvoice(event.getRepairId());
            // Publish INVOICE_CREATED event
            PaymentEvent paymentEvent = new PaymentEvent(
                "INVOICE_CREATED", invoice.getId(), invoice.getAmount()
            );
            kafkaTemplate.send("payment-events", invoice.getId(), paymentEvent);
        }
```
**2. ประมวลผลการชำระเงิน**
```
    Customer → POST /api/v1/payments
        ↓
    Payment Service (Producer) →
        ├─ เรียก Payment Gateway API
        ├─ บันทึกผล transaction ใน PostgreSQL
        └─ Publish "PAYMENT_COMPLETED" event
            ↓
    Consumers:
        ├─ Notification Service → ส่งใบเสร็จทาง email
        ├─ Booking Service → อัพเดทสถานะเป็น "PAID"
        └─ Analytics Service → บันทึกรายได้
```
## Flow 4: การจัดการข้อผิดพลาด (Error Handling Flow)
### Saga Pattern with Compensation
**Distributed Transaction Management**
```java
// หากการชำระเงินล้มเหลว
@KafkaListener(topics = "payment-events")
public void handlePaymentFailed(PaymentFailedEvent event) {
    // Publish compensation events
    BookingCompensationEvent compensation = new BookingCompensationEvent(
        "ROLLBACK_BOOKING", event.getBookingId()
    );
    kafkaTemplate.send("compensation-events", compensation);
}

// Booking Service รับ compensation event
@KafkaListener(topics = "compensation-events")
public void compensateBooking(BookingCompensationEvent event) {
    // Rollback การจอง
    bookingService.cancelBooking(event.getBookingId());
    
    // คืนเงินหากมีการจ่ายล่วงหน้า
    // แจ้งเตือนลูกค้า
}
```
### Retry และ Dead Letter Queue
```java
// Configuration สำหรับ retry mechanism
@Bean
public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory() {
    factory.setCommonErrorHandler(new DefaultErrorHandler(
        new DeadLetterPublishingRecoverer(kafkaTemplate),
        new FixedBackOff(1000L, 3L) // Retry 3 ครั้ง ห่างกัน 1 วินาที
    ));
    return factory;
}
// Consumer with error handling
@KafkaListener(topics = "booking-events")
public void processBooking(BookingEvent event) {
    try {
        bookingService.process(event);
    } catch (RetryableException e) {
        // Kafka จะ retry อัตโนมัติ
        throw e;
    } catch (NonRetryableException e) {
        // ส่งไป DLQ ทันที
        log.error("Non-retryable error", e);
        throw e;
    }
}
```
## สรุปโครงสร้าง Event Flow
| Event Type | Producer | Topic | Consumers | Action |
| :-- | :-- | :-- | :-- | :-- |
| BOOKING_CREATED | Booking Service | booking-events | Notification, Analytics, Audit | ส่งการแจ้งเตือน, บันทึกสถิติ |
| REPAIR_STARTED | Repair Service | repair-events | Status Update, Notification | อัพเดทสถานะ real-time |
| REPAIR_COMPLETED | Repair Service | repair-events | Payment, Notification, Inventory | สร้าง invoice, อัพเดท stock |
| PAYMENT_COMPLETED | Payment Service | payment-events | Notification, Booking, Analytics | ส่งใบเสร็จ, ปิดงาน |
| NOTIFICATION_SENT | Notification Service | notification-events | Analytics, Audit | ติดตามประสิทธิภาพการแจ้งเตือน |

- ระบบนี้รองรับ asynchronous communication, fault tolerance และ scalability สูง  โดยแต่ละ microservice สามารถ scale แยกอิสระตามปริมาณ events ที่ต้องประมวลผล

# การจัดการ transaction ระหว่าง DB กับ Kafka ใน Spring


## การจัดการ Transaction ระหว่าง Database กับ Kafka ใน Spring Boot

การจัดการ transaction ระหว่าง Database และ Kafka ใน Spring Boot ต้องเข้าใจว่า Kafka ไม่รองรับ XA transactions แบบ distributed ดังนั้น Spring จะจัดการ transactions แยกกันแต่ synchronize ให้ทำงานร่วมกัน  มี 3 วิธีหลักในการจัดการ transactions นี้[^1][^2][^3][^4]

## วิธีที่ 1: Database Commit First (Default)

### Configuration

```properties
# application.properties
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.producer.transaction-id-prefix=tx-
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.properties.isolation.level=read_committed

# Database
spring.datasource.url=jdbc:postgresql://localhost:5432/carservice
spring.datasource.username=postgres
spring.datasource.password=password
```


### Transaction Manager Setup

```java
@Configuration
public class TransactionConfig {
    
    // Spring Boot สร้าง transaction managers อัตโนมัติ:
    // 1. transactionManager (JPA/DataSource)
    // 2. kafkaTransactionManager (Kafka)
    
    @Bean
    public DataSourceTransactionManager dstm(DataSource dataSource) {
        return new DataSourceTransactionManager(dataSource);
    }
}
```


### Implementation: Consumer Listener

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class BookingEventListener {
    
    private final BookingRepository bookingRepository;
    private final KafkaTemplate<String, Object> kafkaTemplate;
    private final JdbcTemplate jdbcTemplate;
    
    /**
     * Kafka Listener container เริ่ม Kafka transaction
     * @Transactional เริ่ม DB transaction
     * 
     * ลำดับการ commit:
     * 1. DB commits first
     * 2. Kafka commits second
     * 
     * หาก Kafka commit ล้มเหลว: message จะถูก redelivered
     * ดังนั้น DB operation ต้องเป็น idempotent
     */
    @KafkaListener(
        id = "booking-listener",
        topics = "booking-events",
        groupId = "booking-consumer-group"
    )
    @Transactional("dstm")  // ใช้ DataSource Transaction Manager
    public void handleBookingEvent(BookingEvent event) {
        log.info("Received booking event: {}", event.getEventId());
        
        // 1. บันทึกข้อมูลลง PostgreSQL
        Booking booking = Booking.builder()
            .id(event.getBookingId())
            .customerId(event.getCustomerId())
            .vehicleId(event.getVehicleId())
            .bookingDate(event.getBookingDate())
            .status("CONFIRMED")
            .build();
        
        bookingRepository.save(booking);
        
        // 2. ส่ง notification event ไปยัง Kafka
        // KafkaTemplate จะ synchronize กับ DB transaction
        NotificationEvent notification = NotificationEvent.builder()
            .eventId(UUID.randomUUID().toString())
            .customerId(event.getCustomerId())
            .message("การจองของคุณได้รับการยืนยัน")
            .timestamp(Instant.now())
            .build();
        
        kafkaTemplate.send("notification-events", notification);
        
        // Method จบ: 
        // 1. DB transaction commits
        // 2. Kafka transaction commits
    }
}
```


### Implementation: Producer Service

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class RepairService {
    
    private final RepairRepository repairRepository;
    private final KafkaTemplate<String, Object> kafkaTemplate;
    
    /**
     * Producer-only transaction
     * KafkaTemplate synchronizes กับ DB transaction
     */
    @Transactional("dstm")
    public RepairResponse startRepair(RepairRequest request) {
        // 1. บันทึกข้อมูลการซ่อมใน database
        Repair repair = Repair.builder()
            .id(UUID.randomUUID().toString())
            .bookingId(request.getBookingId())
            .technicianId(request.getTechnicianId())
            .status("IN_PROGRESS")
            .estimatedCost(request.getEstimatedCost())
            .createdAt(LocalDateTime.now())
            .build();
        
        Repair savedRepair = repairRepository.save(repair);
        
        // 2. Publish event ไปยัง Kafka
        // KafkaTemplate จะรอจน DB commit ก่อน
        RepairEvent event = RepairEvent.builder()
            .eventId(UUID.randomUUID().toString())
            .eventType("REPAIR_STARTED")
            .repairId(savedRepair.getId())
            .timestamp(Instant.now())
            .build();
        
        kafkaTemplate.send("repair-events", savedRepair.getId(), event);
        
        // ลำดับการ commit:
        // 1. PostgreSQL transaction commits
        // 2. Kafka transaction commits
        
        return RepairResponse.from(savedRepair);
    }
}
```


## วิธีที่ 2: Kafka Commit First (Nested Transactions)

### Implementation

```java
@Service
@RequiredArgsConstructor
public class PaymentService {
    
    private final PaymentRepository paymentRepository;
    private final JdbcTemplate jdbcTemplate;
    
    /**
     * Outer method ใช้ DataSource Transaction Manager
     * Inner method ใช้ Kafka Transaction Manager
     * 
     * ลำดับการ commit:
     * 1. Kafka commits first
     * 2. DB commits only if Kafka succeeds
     */
    @Transactional("dstm")
    public void processPayment(PaymentRequest request) {
        // 1. บันทึกข้อมูลใน database
        jdbcTemplate.execute(
            "INSERT INTO payments (id, booking_id, amount, status) " +
            "VALUES ('" + request.getId() + "', '" + request.getBookingId() + 
            "', " + request.getAmount() + ", 'PENDING')"
        );
        
        // 2. เรียก inner method เพื่อส่ง Kafka message
        sendPaymentEvent(request);
        
        // Kafka commits ก่อน (จาก inner method)
        // จากนั้น DB commits
    }
    
    @Transactional("kafkaTransactionManager")
    public void sendPaymentEvent(PaymentRequest request) {
        PaymentEvent event = PaymentEvent.builder()
            .eventId(UUID.randomUUID().toString())
            .eventType("PAYMENT_PROCESSED")
            .paymentId(request.getId())
            .amount(request.getAmount())
            .build();
        
        kafkaTemplate.send("payment-events", event);
        
        // Kafka transaction commits เมื่อออกจาก method นี้
    }
}
```


## วิธีที่ 3: Transactional Outbox Pattern

### วิธีการทำงาน

Outbox Pattern แก้ปัญหา dual-write โดยเขียนข้อมูลทั้ง business data และ outbox message ลงใน database ในหนึ่ง transaction จากนั้นใช้กระบวนการแยกต่างหากในการอ่าน outbox และส่งไปยัง Kafka[^3][^5]

### Database Schema

```sql
-- Business table
CREATE TABLE bookings (
    id VARCHAR(36) PRIMARY KEY,
    customer_id VARCHAR(36) NOT NULL,
    vehicle_id VARCHAR(36) NOT NULL,
    booking_date TIMESTAMP NOT NULL,
    status VARCHAR(20) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Outbox table
CREATE TABLE outbox_events (
    id VARCHAR(36) PRIMARY KEY,
    aggregate_type VARCHAR(50) NOT NULL,
    aggregate_id VARCHAR(36) NOT NULL,
    event_type VARCHAR(50) NOT NULL,
    payload JSONB NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed BOOLEAN DEFAULT FALSE,
    processed_at TIMESTAMP
);

CREATE INDEX idx_outbox_processed ON outbox_events(processed, created_at);
```


### Implementation: Write to Outbox

```java
@Service
@RequiredArgsConstructor
public class BookingService {
    
    private final BookingRepository bookingRepository;
    private final OutboxEventRepository outboxEventRepository;
    private final ObjectMapper objectMapper;
    
    /**
     * เขียนทั้ง booking และ outbox event ใน transaction เดียว
     * รับประกัน atomicity
     */
    @Transactional
    public BookingResponse createBooking(BookingRequest request) {
        // 1. สร้าง booking
        Booking booking = Booking.builder()
            .id(UUID.randomUUID().toString())
            .customerId(request.getCustomerId())
            .vehicleId(request.getVehicleId())
            .bookingDate(request.getBookingDate())
            .status("PENDING")
            .build();
        
        Booking savedBooking = bookingRepository.save(booking);
        
        // 2. สร้าง outbox event
        BookingEvent event = BookingEvent.builder()
            .eventId(UUID.randomUUID().toString())
            .eventType("BOOKING_CREATED")
            .bookingId(savedBooking.getId())
            .customerId(savedBooking.getCustomerId())
            .timestamp(Instant.now())
            .build();
        
        OutboxEvent outboxEvent = OutboxEvent.builder()
            .id(event.getEventId())
            .aggregateType("Booking")
            .aggregateId(savedBooking.getId())
            .eventType(event.getEventType())
            .payload(objectMapper.writeValueAsString(event))
            .processed(false)
            .build();
        
        outboxEventRepository.save(outboxEvent);
        
        // Transaction commit: ทั้ง booking และ outbox ถูกบันทึกพร้อมกัน
        
        return BookingResponse.from(savedBooking);
    }
}
```


### Implementation: Outbox Publisher

```java
@Component
@RequiredArgsConstructor
@Slf4j
public class OutboxEventPublisher {
    
    private final OutboxEventRepository outboxEventRepository;
    private final KafkaTemplate<String, String> kafkaTemplate;
    private final ObjectMapper objectMapper;
    
    /**
     * Scheduled task ดึง unprocessed events และส่งไปยัง Kafka
     */
    @Scheduled(fixedDelay = 5000) // ทุก 5 วินาที
    @Transactional
    public void publishOutboxEvents() {
        List<OutboxEvent> events = outboxEventRepository
            .findTop100ByProcessedFalseOrderByCreatedAtAsc();
        
        for (OutboxEvent event : events) {
            try {
                // ส่งไปยัง Kafka
                String topic = determineTopicByEventType(event.getEventType());
                
                kafkaTemplate.send(topic, event.getAggregateId(), event.getPayload())
                    .addCallback(
                        result -> {
                            // สำเร็จ: mark as processed
                            event.setProcessed(true);
                            event.setProcessedAt(Instant.now());
                            outboxEventRepository.save(event);
                            log.info("Published outbox event: {}", event.getId());
                        },
                        ex -> {
                            log.error("Failed to publish outbox event: {}", 
                                event.getId(), ex);
                            // Retry ในรอบถัดไป
                        }
                    );
                
            } catch (Exception e) {
                log.error("Error processing outbox event: {}", event.getId(), e);
            }
        }
    }
    
    private String determineTopicByEventType(String eventType) {
        if (eventType.startsWith("BOOKING")) return "booking-events";
        if (eventType.startsWith("REPAIR")) return "repair-events";
        if (eventType.startsWith("PAYMENT")) return "payment-events";
        return "default-events";
    }
}
```


## การจัดการ Error และ Rollback

### Retry Mechanism

```java
@Configuration
public class KafkaErrorHandlingConfig {
    
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> 
        kafkaListenerContainerFactory(
            ConsumerFactory<String, Object> consumerFactory,
            KafkaTemplate<String, Object> kafkaTemplate) {
        
        ConcurrentKafkaListenerContainerFactory<String, Object> factory =
            new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        
        // Error handler with retry and DLQ
        DefaultErrorHandler errorHandler = new DefaultErrorHandler(
            new DeadLetterPublishingRecoverer(kafkaTemplate),
            new FixedBackOff(2000L, 3L) // Retry 3 ครั้ง ห่างกัน 2 วินาที
        );
        
        // กำหนด exceptions ที่ควร retry
        errorHandler.addRetryableExceptions(
            TransientDataAccessException.class,
            TimeoutException.class
        );
        
        // กำหนด exceptions ที่ไม่ควร retry (ส่งไป DLQ ทันที)
        errorHandler.addNotRetryableExceptions(
            IllegalArgumentException.class,
            JsonProcessingException.class
        );
        
        factory.setCommonErrorHandler(errorHandler);
        return factory;
    }
}
```


### Idempotent Consumer

```java
@Service
@RequiredArgsConstructor
public class IdempotentBookingConsumer {
    
    private final BookingRepository bookingRepository;
    private final ProcessedMessageRepository processedMessageRepository;
    
    @KafkaListener(topics = "booking-events")
    @Transactional
    public void handleBooking(BookingEvent event) {
        // ตรวจสอบว่าเคย process message นี้แล้วหรือไม่
        if (processedMessageRepository.existsById(event.getEventId())) {
            log.warn("Duplicate message detected: {}", event.getEventId());
            return; // Skip duplicate
        }
        
        // Process booking
        Booking booking = bookingRepository.findById(event.getBookingId())
            .orElse(new Booking());
        booking.setStatus("CONFIRMED");
        bookingRepository.save(booking);
        
        // บันทึกว่าได้ process message นี้แล้ว
        ProcessedMessage processed = new ProcessedMessage(
            event.getEventId(), 
            Instant.now()
        );
        processedMessageRepository.save(processed);
    }
}
```


## สรุปการเปรียบเทียบ
```HTML
| แนวทาง | ข้อดี | ข้อเสีย | Use Case |
| :-- | :-- | :-- | :-- |
| DB Commit First | ง่าย, built-in support | Message อาจ redelivered, ต้อง idempotent | Consumer ที่ไม่ซับซ้อน |
| Kafka Commit First | Kafka guarantees ก่อน | DB อาจล้มเหลวหลัง Kafka commit | Critical event publishing |
| Outbox Pattern | Guaranteed delivery, true atomicity | ซับซ้อนกว่า, latency สูงขึ้น | Mission-critical systems |
```
สำหรับระบบศูนย์บริการรถยนต์ ควรใช้ Outbox Pattern สำหรับ critical operations เช่น payment และใช้ DB Commit First สำหรับ operations ทั่วไปเพื่อความเรียบง่าย




1. ฐานข้อมูล PostgreSQL ออกแบบตามหลักการ normalization เพื่อลดความซ้าซ้อนของข้อมูล  
- ใช้ data types ที่เหมาะสม เช่น JSONB สำหรับ JSON data, UUID สำหรับ unique identifiers และ ARRAY สำหรับข้อมูลแบบรายการ  
- ควรใช้ connection pooling ด้วยเครื่องมืออย่าง PgBouncer / Pgpool-II เพื่อจัดการ concurrent connections ได้อย่างมีประสิทธิภาพ  
- สร้าง indexes แบบมีกลยุทธ์โดยใช้ B-tree หรือ hash indexes สำหรับ high-read operations และ partition tables ขนาดใหญ่เพื่อเพิ่มประสิทธิภาพ

1. Redis Cache
- Redis ทำหน้าที่เป็น distributed cache สำหรับลด response time ของ microservices 
- ใช้ query caching pattern โดย deploy Redis cache แยกสำหรับแต่ละ microservice  
- กำหนด eviction policies ที่เหมาะสม เช่น LRU การจัดการ transaction ระหว่าง DB กับ Kafka ใน Spring(Least Recently Used), LFU (Least Frequently Used) หรือ TTL (Time-to-Live)  
- ใช้ Redis Pub/Sub สำหรับ cache synchronization ระหว่าง microservices เพื่อให้ข้อมูลใน cache มีความ consistent


5. การพัฒนา
- การออกแบบฐานข้อมูลศูนย์บริการรถยนต์ มี entities หลัก 
- Customers (ลูกค้า),
- Vehicles (รถยนต์),
- Services (บริการ),
- Bookings (การจอง),
- Payments (การชำระเงิน),
- Employees (พนักงาน)
- Repair Records (บันทึกการซ่อม)  ใช้ constraints อย่าง NOT NULL, UNIQUE และ CHECK เพื่อรักษา data integrity  
- ระบบควรรองรับการจองนัดหมาย
- ระบบการตรวจสอบสถานะการซ่อม
- ระบบการชำระเงินออนไลน์
- ระบบการติดตามประวัติการบริการ
